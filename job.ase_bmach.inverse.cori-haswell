#!/bin/bash 
#
# job script for nersc cori
#
#SBATCH -A m1041
#SBATCH -J ase_bmach-inverse
#SBATCH --qos=debug
##SBATCH --qos=regular
#SBATCH --time=0:30:00
#SBATCH --nodes=4
#SBATCH --tasks-per-node=32
#SBATCH --constraint=haswell
#SBATCH --mail-type=ALL
#SBATCH --mail-user=skachuck@umich.edu

#get the job id no
export JOBNO=$SLURM_JOB_ID


#module unload PrgEnv-gnu
#module unload craype-haswell
#module load PrgEnv-intel
#module load craype-mic-knl
#module load python
# (DFM -- 1/10/21) backup to older version of python
module unload python
module load python

export PETSC_DIR=/global/common/software/m1041/petsc_install/petsc_haswell_gnu/
export PETSC_ARCH=""
export LD_LIBRARY_PATH=${PYTHON_DIR}/lib:${LD_LIBRARY_PATH}

#first submit the next job, dependent on this one
#sbatch --dependency=afternotok:$JOBNO ./job.ase_ismip6-5.noHEvolve.dam.cori-haswell

NCORE=$((32 * $SLURM_JOB_NUM_NODES))
echo "n_node: $SLURM_JOB_NUM_NODES , n_core: $NCORE"
DRIVER=/global/common/software/m1041/BISICLES/haswell/bin/driver2d.Linux.64.CC.ftn.OPT.MPI.PETSC.ex
#DRIVER=$BISICLES_HOME/BISICLESdamage-public/code/exec2D/driver2d.Linux.64.CC.ftn.OPT.MPI.PETSC.ex
NAME=ase_bmach.inverse
RUNDIR=$SLURM_SUBMIT_DIR/$SLURM_JOB_ID
mkdir -p $RUNDIR
INFILEBASE=inputs.$NAME
INFILE=$INFILEBASE"."$SLURM_JOB_ID
cp $SLURM_SUBMIT_DIR/$INFILEBASE $RUNDIR/$INFILE
cp $SLURM_SUBMIT_DIR/.petscrc $RUNDIR/
cp /global/homes/s/skachuck/.petscrc $RUNDIR/
cd $RUNDIR

export CH_TIMER=1
export CH_OUTPUT_INTERVAL=999
export PYTHONPATH=$PWD:$PYTHONPATH

echo "srun -n $NCORE $DRIVER $INFILE"
srun -n $NCORE $DRIVER $INFILE

